Load task dataset for [a+b mod 97]...
== Training Starts ðŸ§¨ ==
num. params in base model: [0.423296M]
num. params in amplifier: [16769]
Num. of epochs: [111111]
  0%|                                                                                                                                                                                                                                                                                                                                                                    | 0/111111 [00:00<?, ?it/s]
> /scratch/homes/sfan/NeuralOptGrok/src/train.py(190)trans_module_grad()
-> if hasattr(module.__getattr__(attr), "grad"):
''
Decoder(
  (token_embeddings): Embedding(101, 128)
  (position_embeddings): Embedding(5, 128)
  (layers): ModuleList(
    (0-1): 2 x Block(
      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
  )
  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (head): Linear(in_features=128, out_features=101, bias=False)
)
  0%|                                                                                                                                                                                                                                                                                                                                                                    | 0/111111 [01:05<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/homes/sfan/NeuralOptGrok/src/run.py", line 106, in <module>
    run(args)
  File "/scratch/homes/sfan/NeuralOptGrok/src/run.py", line 91, in run
    train(args,
  File "/scratch/homes/sfan/NeuralOptGrok/src/train.py", line 105, in train
    amp_update(amp, meta_optimizer, outer_loader, model_copy, opt, inner_batch=input)
  File "/scratch/homes/sfan/NeuralOptGrok/src/train.py", line 214, in amp_update
    trans_module_grad(model_copy, amp)
  File "/scratch/homes/sfan/NeuralOptGrok/src/train.py", line 190, in trans_module_grad
    if hasattr(module.__getattr__(attr), "grad"):
  File "/scratch/homes/sfan/NeuralOptGrok/src/train.py", line 190, in trans_module_grad
    if hasattr(module.__getattr__(attr), "grad"):
  File "/opt/conda/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/opt/conda/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit